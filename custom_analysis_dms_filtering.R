
custom_analysis_dms_filtering <- function(site_col_name=site_col_name, species_col_name=species_col_name, wd=wd){
  
  setwd(wd)
  
  library(colorspace)
  library(gg3D)
  library(patchwork)
  library(gridExtra)
  library(RColorBrewer)
  library(circlize) 
  library(scatterpie)
  library(tanggle)
  library(RSplitsTree)
  library(qpdf)
  library(ggplot2)
  library(dplyr)
  library(data.table)
  library(ggrepel)
  library(tidyverse)
  library(ggspatial)
  library(readxl)
  library(heatmaply)
  library(circlize)
  library(ComplexHeatmap)
  library(igraph)
  library(SNPRelate)
  library(geosphere)
  library(reshape2)
  library(vegan)
  library(openxlsx)
  library(ggpubr)
  library(RRtools)
  library(ggthemes)
  library(RColorBrewer)
  library(ozmaps)
  library(adegenet)
  library(tidyr)
  library(diveRsity)
  library(RRtools)
  library(LEA)
  
setup_variables <- read.xlsx("0_setup_variables.xlsx", colNames = TRUE)
maindir <- setup_variables[1, 2]
species <- setup_variables[2, 2]
dataset <- setup_variables[3, 2]
RandRbase <- ""
raw_meta_path <- setup_variables[4, 2]

species_col_name <- species_col_name

site_col_name <- site_col_name


site_distances <- setup_variables[7, 2] %>% as.numeric()
remove_pops_less_than_n5 <- setup_variables[8, 2]
downsample <- setup_variables[9, 2]
samples_per_pop <- setup_variables[10, 2] %>% as.numeric()
locus_miss <- setup_variables[11, 2] %>% as.numeric()
sample_miss <- setup_variables[12, 2] %>% as.numeric()
maf_val <- setup_variables[13, 2] %>% as.numeric()
clonal_threshold <- setup_variables[14, 2] %>% as.numeric()
custom_meta <- setup_variables[15, 2] 


setwd(maindir)

topskip   <- 6
nmetavar  <- 22

subsubdirectories <- c(paste0("outputs_",site_col_name,"_",species_col_name,"/plots"),
                       paste0("outputs_",site_col_name,"_",species_col_name,"/tables"),
                       paste0("outputs_",site_col_name,"_",species_col_name,"/r_files"))

# Check and create subdirectories if they don't exist
for (subdir in subsubdirectories) {
  
  subdirectory_path <- file.path(paste0(species,'/',subdir))
  
  if (!dir.exists(subdirectory_path)) {
    dir.create(subdirectory_path, recursive = TRUE)
    cat(paste("Created directory:", subdirectory_path, "\n"))
  } else {
    cat(paste("Directory already exists:", subdirectory_path, "\n"))
  }
}
devtools::source_url("https://github.com/eilishmcmaster/SoS_functions/blob/main/sos_functions.R?raw=TRUE")

# note that this loads scripts generated by SY to automate / make RnR summary reports from DArTseq data. Should probably be put onto Git
# load("PSFsaved_scripts4autom2.RData")
### Import and QC ####

#Load data and quality filter loci and samples
d1        <- new.read.dart.xls.onerow(RandRbase,species,dataset,topskip, euchits=FALSE, altcount=TRUE)
qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8)
#fix(report.dart.qc.stats) # need to add species variable to the qc_dir and anything else after the paste(basedir, function)

d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=locus_miss)
qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)

d3        <- sample.one.snp.per.locus.random(d2, seed=214241)
qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)

#Load meta data and attach to dart data
m1        <- read.meta.data.full.analyses.df(d3, RandRbase, species, dataset)

m1$analyses[,site_col_name] <- gsub(" ", "_", m1$analyses[,site_col_name]) #this makes sure any spaces are replace by underscore

write.table(data.frame(sample=d3$sample_names[!(d3$sample_names %in% m1$sample_names)]), 
            paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/samples_in_dart_not_in_meta.tsv"), sep="\t", row.names = FALSE)

dm        <- dart.meta.data.merge(d3, m1)

# remove samples that are NA for site variable 
samples_with_site_variable <- dm$sample_names[!is.na(dm$meta$analyses[,site_col_name])]
dms2 <- remove.by.list(dm, samples_with_site_variable)



dms <- dms2
treatment <- dms$treatment
# get mean values of lat and long per species site 

# # Original Site Summary
unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
  group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
  dplyr::summarize(n_unfiltered = sum(n()),
                   lat = mean(as.numeric(lat), na.rm=TRUE),
                   long = mean(as.numeric(long),na.rm=TRUE),
                   .groups = 'drop') %>%
  filter(n_unfiltered > 0) %>%
  as.data.frame()



### Remove samples with high missingness ####################################### 

samples_high_missing <- dms$sample_names[which(rowMeans(is.na(dms$gt))>sample_miss)]

print(paste0("Found ", length(samples_high_missing), " samples with missingness over ",sample_miss,". removing from analysis"  ))

write.table(data.frame(sample=samples_high_missing, sample_miss=rowMeans(is.na(dms$gt))[which(rowMeans(is.na(dms$gt))>sample_miss)]), 
            paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/high_missing_samples_removed.tsv"), sep="\t", row.names = FALSE)


dms <- remove.by.missingness(dms, sample_miss)
sites_high_missing_samples_removed <- table(dms$meta$analyses[,site_col_name])


### re-analyse #####

if (!length(d1$sample_names)==length(dms$sample_names)){
  print("Hold Up Cowboy! you've removed samples from previous filtering. let's reanalyse the dataset :)")
  
  d1old <- d1
  d1 <- remove.by.list(d1, dms$sample_names)
  qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8)
  d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=locus_miss)
  qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)
  d3        <- sample.one.snp.per.locus.random(d2, seed=214241)
  qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)
  
  #Load meta data and attach to dart data
  m1        <- read.meta.data.full.analyses.df(d3, RandRbase, species, dataset)
  m1$analyses[,site_col_name] <- gsub(" ", "_", m1$analyses[,site_col_name]) #this makes sure any spaces are replace by underscore
  write.table(data.frame(sample=d3$sample_names[!(d3$sample_names %in% m1$sample_names)]), 
              paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/samples_in_dart_not_in_meta.tsv"), sep="\t", row.names = FALSE)
  dm        <- dart.meta.data.merge(d3, m1)
  
  # remove samples that are NA for site variable 
  samples_with_site_variable <- dm$sample_names[!is.na(dm$meta$analyses[,site_col_name])]
  dmsnew <- remove.by.list(dm, samples_with_site_variable)
  
  print(paste0("originally you had ",length(d1old$sample_names), " samples with ",  length(d1old$locus_names), " filtered SNPs"))
  print(paste0("Now you have ",length(dmsnew$sample_names), " samples with ",  length(dmsnew$locus_names), " filtered SNPs. Sweet as!"))
  
  dms <- dmsnew 
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
} else {
  print("No samples removed. Not re-analysing")
}


### Remove samples with high missingness ####################################### 

samples_high_missing <- dms$sample_names[which(rowMeans(is.na(dms$gt))>sample_miss)]

print(paste0("Found ", length(samples_high_missing), " samples with missingness over ",sample_miss,". removing from analysis"  ))

write.table(data.frame(sample=samples_high_missing, sample_miss=rowMeans(is.na(dms$gt))[which(rowMeans(is.na(dms$gt))>sample_miss)]), 
            paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/high_missing_samples_removed.tsv"), sep="\t", row.names = FALSE)


dms <- remove.by.missingness(dms, sample_miss)
sites_high_missing_samples_removed <- table(dms$meta$analyses[,site_col_name])


### re-analyse #####

if (!length(d1$sample_names)==length(dms$sample_names)){
  print("Hold Up Cowboy! you've removed samples from previous filtering. let's reanalyse the dataset :)")
  
  d1old <- d1
  d1 <- remove.by.list(d1, dms$sample_names)
  qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8)
  d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=locus_miss)
  qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)
  d3        <- sample.one.snp.per.locus.random(d2, seed=214241)
  qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)
  
  #Load meta data and attach to dart data
  m1        <- read.meta.data.full.analyses.df(d3, RandRbase, species, dataset)
  m1$analyses[,site_col_name] <- gsub(" ", "_", m1$analyses[,site_col_name]) #this makes sure any spaces are replace by underscore
  write.table(data.frame(sample=d3$sample_names[!(d3$sample_names %in% m1$sample_names)]), 
              paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/samples_in_dart_not_in_meta.tsv"), sep="\t", row.names = FALSE)
  dm        <- dart.meta.data.merge(d3, m1)
  
  # remove samples that are NA for site variable 
  samples_with_site_variable <- dm$sample_names[!is.na(dm$meta$analyses[,site_col_name])]
  dmsnew <- remove.by.list(dm, samples_with_site_variable)
  
  print(paste0("originally you had ",length(d1old$sample_names), " samples with ",  length(d1old$locus_names), " filtered SNPs"))
  print(paste0("Now you have ",length(dmsnew$sample_names), " samples with ",  length(dmsnew$locus_names), " filtered SNPs. Sweet as!"))
  
  dms <- dmsnew 
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
} else {
  print("No samples removed. Not re-analysing")
}


### Identify and remove clones  ################################### 
# find and remove clones using SNPrelate kinship 
# then keep the ramet with the lowest missingnenss for each genet
#calculate kinship by population 
# VERY important that the population groups are true genetic groups and not conglomerates of multiple genetic groups
kin <- individual_kinship_by_pop(dms, RandRbase, species, dataset, dms$meta$analyses[,site_col_name], maf=maf_val, mis=locus_miss, as_bigmat=TRUE)
kin[is.na(kin)] <- 0
length(dms$locus_names)


kin <- round(kin,3)
kin2 <- melt(kin)
kin2 <- kin2[which(!kin2$Var1==kin2$Var2),]
kin2 <- kin2[rev(order(kin2$value)),]
kin2[kin2$value>0,]


dist_raw <- as.matrix(dist(dms$gt, diag=TRUE))
distship_df <- 1- (dist_raw/max(dist_raw, na.rm=TRUE)) %>% as.data.frame() %>% round(3)
distship_df$sample <- rownames(distship_df)
distship_df <- melt(distship_df)
distship_df <- distship_df[which(!distship_df$sample==distship_df$variable),]
distship_df <- distship_df[rev(order(distship_df$value)),]
distship_df
length(dms$locus_names)

# clonal_threshold <- 0.2

# Finding the clones
kin3 <- ifelse(kin < clonal_threshold, 0, 1)

# cluster the clones 
network <- graph_from_adjacency_matrix(kin3, mode="undirected", diag=F,weighted=T) #makes the network based on k>0.4

ceb <- cluster_fast_greedy(network) # makes cluster groupings



# get clones 
clones <-as.data.frame(cbind(genet=ceb$membership, sample=ceb$names)) #get the clones from the network as a df
clones_out <- merge(clones, dms$meta$analyses[,c("sample","lat","long",site_col_name,species_col_name)], by="sample") #add some metadata
clones_out <- clones_out[order(as.numeric(clones_out$genet)),] #order the table by genet 
clones_out$genet <- as.numeric(clones_out$genet)

write.xlsx(clones_out, paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/PLINK_clones.xlsx"), asTable = FALSE, overwrite = TRUE)


# Now remove clones from the dataset for future analyses, keeping the sample which is the 
clonenum <- which(duplicated(clones_out$genet)==TRUE) 
clonenum2 <- unique(clones_out$genet[clonenum]) #identify which genets have multiple ramets


if (isFALSE(length(clonenum2)>0)){
  print("No genets with multiple ramets detected")
} else{
  keepsamps <- c()
  for (w in 1:length(clonenum2)){
    samps <- clones_out$sample[which(clones_out$genet==clonenum2[w])] #identify the NSW samples that are clones
    num_missing <- data.frame(matrix(ncol=2, nrow=length(samps)))
    colnames(num_missing) <- c("NSWNum", "sumNA")
    for (s in 1: length(samps)){
      num <- which(dms$sample_names==samps[s])
      num_missing$NSWNum[s] <- samps[s]
      num_missing$sumNA[s] <- sum(is.na(dms$gt[num,])==TRUE)
    }
    num_missing <- num_missing[order(num_missing$sumNA),]   #now keep the sample with the fewest NA's for dms$gt
    keepsamps[w] <- num_missing$NSWNum[1]
    
  }
  
  print(paste0("identified ", length(keepsamps), " genets with multiple ramets. Keeping the following ramets in dataset: ", list(keepsamps)))
  
  allgenets <- 1:max(clones_out$genet)
  noclonegenets <- which(!allgenets %in% clonenum2) #identify all genets that don't have multiple samples
  noclonesamps <- clones_out$sample[which(clones_out$genet %in% noclonegenets)] #these are NSW numbers with no clones identified. then add the clones we want to keep with these samples
  
  SampstoKeep <- c(keepsamps, noclonesamps) #this is our final list of samples which have removed clones and selected ramets of each genet with the lowest number of NA loci in dms$gt
  
  dms2 <- remove.by.list(dm, SampstoKeep)
  
  dms <- dms2
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
}


### Remove pops with less than five samples? #####

if(remove_pops_less_than_n5=="TRUE"){
  not_n5_sites <- as.vector(names(which(sites_high_missing_samples_removed<samples_per_pop))) #remove groups where n<=1
  not_n5_samples <- dms$sample_names[which(!(dms$meta$analyses[,site_col_name] %in% not_n5_sites))]
  dms <- remove.by.list(dms, not_n5_samples)
  
  dms_no_n1_sites <- dms
}else{
  # make dms where there are no n=1 site
  not_n1_sites <- as.vector(unfiltered_site_summary[unfiltered_site_summary$n_unfiltered<=1,2]) #remove groups where n<=1
  not_n1_samples <- dms$sample_names[which(!(dms$meta$analyses[,site_col_name] %in% not_n1_sites))]
  dms_no_n1_sites <- remove.by.list(dms, not_n1_samples)
}




### re-analyse #####

if (!length(d1$sample_names)==length(dms$sample_names)){
  print("Hold Up Cowboy! you've removed samples from previous filtering. let's reanalyse the dataset :)")
  
  d1old <- d1
  d1 <- remove.by.list(d1, dms$sample_names)
  qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8)
  d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=locus_miss)
  qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)
  d3        <- sample.one.snp.per.locus.random(d2, seed=214241)
  qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)
  
  #Load meta data and attach to dart data
  m1        <- read.meta.data.full.analyses.df(d3, RandRbase, species, dataset)
  m1$analyses[,site_col_name] <- gsub(" ", "_", m1$analyses[,site_col_name]) #this makes sure any spaces are replace by underscore
  write.table(data.frame(sample=d3$sample_names[!(d3$sample_names %in% m1$sample_names)]), 
              paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/samples_in_dart_not_in_meta.tsv"), sep="\t", row.names = FALSE)
  dm        <- dart.meta.data.merge(d3, m1)
  
  # remove samples that are NA for site variable 
  samples_with_site_variable <- dm$sample_names[!is.na(dm$meta$analyses[,site_col_name])]
  dmsnew <- remove.by.list(dm, samples_with_site_variable)
  
  print(paste0("originally you had ",length(d1old$sample_names), " samples with ",  length(d1old$locus_names), " filtered SNPs"))
  print(paste0("Now you have ",length(dmsnew$sample_names), " samples with ",  length(dmsnew$locus_names), " filtered SNPs. Sweet as!"))
  
  dms <- dmsnew 
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
} else {
  print("No samples removed. Not re-analysing")
}





### Now because I'm pedantic, re-run high missingness and clones too:
### Remove samples with high missingness ####################################### 

samples_high_missing <- dms$sample_names[which(rowMeans(is.na(dms$gt))>sample_miss)]

print(paste0("Found ", length(samples_high_missing), " samples with missingness over ",sample_miss,". removing from analysis"  ))

write.table(data.frame(sample=samples_high_missing, sample_miss=rowMeans(is.na(dms$gt))[which(rowMeans(is.na(dms$gt))>sample_miss)]), 
            paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/high_missing_samples_removed.tsv"), sep="\t", row.names = FALSE)


dms <- remove.by.missingness(dms, sample_miss)
sites_high_missing_samples_removed <- table(dms$meta$analyses[,site_col_name])


### re-analyse #####

if (!length(d1$sample_names)==length(dms$sample_names)){
  print("Hold Up Cowboy! you've removed samples from previous filtering. let's reanalyse the dataset :)")
  
  d1old <- d1
  d1 <- remove.by.list(d1, dms$sample_names)
  qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8)
  d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=locus_miss)
  qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)
  d3        <- sample.one.snp.per.locus.random(d2, seed=214241)
  qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)
  
  #Load meta data and attach to dart data
  m1        <- read.meta.data.full.analyses.df(d3, RandRbase, species, dataset)
  m1$analyses[,site_col_name] <- gsub(" ", "_", m1$analyses[,site_col_name]) #this makes sure any spaces are replace by underscore
  write.table(data.frame(sample=d3$sample_names[!(d3$sample_names %in% m1$sample_names)]), 
              paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/samples_in_dart_not_in_meta.tsv"), sep="\t", row.names = FALSE)
  dm        <- dart.meta.data.merge(d3, m1)
  
  # remove samples that are NA for site variable 
  samples_with_site_variable <- dm$sample_names[!is.na(dm$meta$analyses[,site_col_name])]
  dmsnew <- remove.by.list(dm, samples_with_site_variable)
  
  print(paste0("originally you had ",length(d1old$sample_names), " samples with ",  length(d1old$locus_names), " filtered SNPs"))
  print(paste0("Now you have ",length(dmsnew$sample_names), " samples with ",  length(dmsnew$locus_names), " filtered SNPs. Sweet as!"))
  
  dms <- dmsnew 
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
} else {
  print("No samples removed. Not re-analysing")
}





### Now because I'm pedantic, re-run high missingness and clones too:
### Identify and remove clones  ################################### 
# find and remove clones using SNPrelate kinship 
# then keep the ramet with the lowest missingnenss for each genet

#calculate kinship by population 
# VERY important that the population groups are true genetic groups and not conglomerates of multiple genetic groups
kin <- individual_kinship_by_pop(dms, RandRbase, species, dataset, dms$meta$analyses[,site_col_name], maf=0.1, mis=locus_miss, as_bigmat=TRUE)
kin[is.na(kin)] <- 0
# Finding the clones
kin3 <- ifelse(kin < clonal_threshold, 0, 1)

# cluster the clones 
network <- graph_from_adjacency_matrix(kin3, mode="undirected", diag=F,weighted=T) #makes the network based on k>0.4

ceb <- cluster_fast_greedy(network) # makes cluster groupings

# get clones 
clones <-as.data.frame(cbind(genet=ceb$membership, sample=ceb$names)) #get the clones from the network as a df
clones_out <- merge(clones, dms$meta$analyses[,c("sample","lat","long",site_col_name,species_col_name)], by="sample") #add some metadata
clones_out <- clones_out[order(as.numeric(clones_out$genet)),] #order the table by genet 
clones_out$genet <- as.numeric(clones_out$genet)

write.xlsx(clones_out, paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/PLINK_clones.xlsx"), asTable = FALSE, overwrite = TRUE)


# Now remove clones from the dataset for future analyses, keeping the sample which is the 
clonenum <- which(duplicated(clones_out$genet)==TRUE) 
clonenum2 <- unique(clones_out$genet[clonenum]) #identify which genets have multiple ramets


if (isFALSE(length(clonenum2)>0)){
  print("No genets with multiple ramets detected")
} else{
  keepsamps <- c()
  for (w in 1:length(clonenum2)){
    samps <- clones_out$sample[which(clones_out$genet==clonenum2[w])] #identify the NSW samples that are clones
    num_missing <- data.frame(matrix(ncol=2, nrow=length(samps)))
    colnames(num_missing) <- c("NSWNum", "sumNA")
    for (s in 1: length(samps)){
      num <- which(dms$sample_names==samps[s])
      num_missing$NSWNum[s] <- samps[s]
      num_missing$sumNA[s] <- sum(is.na(dms$gt[num,])==TRUE)
    }
    num_missing <- num_missing[order(num_missing$sumNA),]   #now keep the sample with the fewest NA's for dms$gt
    keepsamps[w] <- num_missing$NSWNum[1]
    
  }
  
  print(paste0("identified ", length(keepsamps), " genets with multiple ramets. Keeping the following ramets in dataset: ", list(keepsamps)))
  
  allgenets <- 1:max(clones_out$genet)
  noclonegenets <- which(!allgenets %in% clonenum2) #identify all genets that don't have multiple samples
  noclonesamps <- clones_out$sample[which(clones_out$genet %in% noclonegenets)] #these are NSW numbers with no clones identified. then add the clones we want to keep with these samples
  
  SampstoKeep <- c(keepsamps, noclonesamps) #this is our final list of samples which have removed clones and selected ramets of each genet with the lowest number of NA loci in dms$gt
  
  dms2 <- remove.by.list(dm, SampstoKeep)
  
  dms <- dms2
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
}


### Remove pops with less than five samples? #####

if(remove_pops_less_than_n5=="TRUE"){
  not_n5_sites <- as.vector(names(which(sites_high_missing_samples_removed<samples_per_pop))) #remove groups where n<=1
  not_n5_samples <- dms$sample_names[which(!(dms$meta$analyses[,site_col_name] %in% not_n5_sites))]
  dms <- remove.by.list(dms, not_n5_samples)
  
  dms_no_n1_sites <- dms
}else{
  # make dms where there are no n=1 site
  not_n1_sites <- as.vector(unfiltered_site_summary[unfiltered_site_summary$n_unfiltered<=1,2]) #remove groups where n<=1
  not_n1_samples <- dms$sample_names[which(!(dms$meta$analyses[,site_col_name] %in% not_n1_sites))]
  dms_no_n1_sites <- remove.by.list(dms, not_n1_samples)
}




### re-analyse #####

if (!length(d1$sample_names)==length(dms$sample_names)){
  print("Hold Up Cowboy! you've removed samples from previous filtering. let's reanalyse the dataset :)")
  
  d1old <- d1
  d1 <- remove.by.list(d1, dms$sample_names)
  qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8)
  d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=locus_miss)
  qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)
  d3        <- sample.one.snp.per.locus.random(d2, seed=214241)
  qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)
  
  #Load meta data and attach to dart data
  m1        <- read.meta.data.full.analyses.df(d3, RandRbase, species, dataset)
  m1$analyses[,site_col_name] <- gsub(" ", "_", m1$analyses[,site_col_name]) #this makes sure any spaces are replace by underscore
  write.table(data.frame(sample=d3$sample_names[!(d3$sample_names %in% m1$sample_names)]), 
              paste0(species,"/outputs_",site_col_name,"_",species_col_name,"/tables/samples_in_dart_not_in_meta.tsv"), sep="\t", row.names = FALSE)
  dm        <- dart.meta.data.merge(d3, m1)
  
  # remove samples that are NA for site variable 
  samples_with_site_variable <- dm$sample_names[!is.na(dm$meta$analyses[,site_col_name])]
  dmsnew <- remove.by.list(dm, samples_with_site_variable)
  
  print(paste0("originally you had ",length(d1old$sample_names), " samples with ",  length(d1old$locus_names), " filtered SNPs"))
  print(paste0("Now you have ",length(dmsnew$sample_names), " samples with ",  length(dmsnew$locus_names), " filtered SNPs. Sweet as!"))
  
  dms <- dmsnew 
  treatment <- dms$treatment
  # get mean values of lat and long per species site 
  
  # # Original Site Summary
  unfiltered_site_summary <- dms2$meta$analyses %>% as.data.frame()%>%
    group_by(!!sym(species_col_name), !!sym(site_col_name)) %>%
    dplyr::summarize(n_unfiltered = sum(n()),
                     lat = mean(as.numeric(lat), na.rm=TRUE),
                     long = mean(as.numeric(long),na.rm=TRUE),
                     .groups = 'drop') %>%
    filter(n_unfiltered > 0) %>%
    as.data.frame()
  
} else {
  print("No samples removed. Not re-analysing")
}



return(dms)
}